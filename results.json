{
    "ED": {
        "aquaint": {
            "gpt-4-0613": {
                "test/accuracy_step": {
                    "mean": 0.45519203413940257,
                    "error": 0.036984352773826445
                }
            },
            "gpt-3.5-turbo-0613": {
                "test/accuracy_step": {
                    "mean": 0.39829302987197723,
                    "error": 0.036273115220483626
                }
            }
        },
        "msnbc": {
            "gpt-3.5-turbo-0613": {
                "test/accuracy_step": {
                    "mean": 0.6282642089093702,
                    "error": 0.03763440860215056
                }
            },
            "gpt-3.5-turbo-0301": {
                "test/accuracy_step": {
                    "mean": 0.49615975422427033,
                    "error": 0.038402457757296476
                }
            },
            "davinci-002": {
                "test/accuracy_step": {
                    "mean": 0.018433179723502304,
                    "error": 0.010752688172043012
                }
            },
            "gpt-3.5-turbo-instruct-0914": {
                "test/accuracy_step": {
                    "mean": 0.5130568356374808,
                    "error": 0.038402457757296476
                }
            },
            "gpt-4-0613": {
                "test/accuracy_step": {
                    "mean": 0.6251920122887865,
                    "error": 0.036866359447004615
                }
            },
            "text-davinci-003": {
                "test/accuracy_step": {
                    "mean": 0.49615975422427033,
                    "error": 0.038402457757296476
                }
            }
        },
        "ace2004": {
            "davinci-002": {
                "test/accuracy_step": {
                    "mean": 0.016666666666666666,
                    "error": 0.01875
                }
            },
            "gpt-3.5-turbo-0301": {
                "test/accuracy_step": {
                    "mean": 0.4791666666666667,
                    "error": 0.06458333333333333
                }
            },
            "gpt-4-0613": {
                "test/accuracy_step": {
                    "mean": 0.5541666666666667,
                    "error": 0.06250000000000003
                }
            },
            "gpt-3.5-turbo-0613": {
                "test/accuracy_step": {
                    "mean": 0.6541666666666667,
                    "error": 0.060416666666666674
                }
            },
            "gpt-3.5-turbo-instruct-0914": {
                "test/accuracy_step": {
                    "mean": 0.49166666666666664,
                    "error": 0.06250000000000003
                }
            },
            "text-davinci-003": {
                "test/accuracy_step": {
                    "mean": 0.43333333333333335,
                    "error": 0.0625
                }
            }
        },
        "wiki": {
            "gpt-3.5-turbo-0613": {
                "test/accuracy_step": {
                    "mean": 0.388905195186381,
                    "error": 0.01152039917816261
                }
            },
            "gpt-4-0613": {
                "test/accuracy_step": {
                    "mean": 0.3338714411505723,
                    "error": 0.011147856433389253
                }
            }
        },
        "aida": {
            "gpt-4-0613": {
                "test/accuracy_step": {
                    "mean": 0.5897435897435898,
                    "error": 0.014381270903010057
                }
            },
            "gpt-3.5-turbo-0613": {
                "test/accuracy_step": {
                    "mean": 0.5663322185061316,
                    "error": 0.014381270903010057
                }
            }
        },
        "clueweb": {
            "gpt-4-0613": {
                "test/accuracy_step": {
                    "mean": 0.404183393196704,
                    "error": 0.013839002746672296
                }
            },
            "gpt-3.5-turbo-0613": {
                "test/accuracy_step": {
                    "mean": 0.4404140414041404,
                    "error": 0.00920364722557862
                }
            }
        }
    },
    "IE": {
        "synthie": {
            "text-davinci-003": {
                "test_0/precision_step": {
                    "mean": 0.18903281231168567,
                    "error": 0.005368024767381116
                },
                "test_0/recall_step": {
                    "mean": 0.18023005185606672,
                    "error": 0.0052173210178238505
                },
                "test_0/f1_step": {
                    "mean": 0.18306836377007824,
                    "error": 0.005207258500864856
                }
            },
            "gpt-4-0613": {
                "test_0/precision_step": {
                    "mean": 0.44470710323232804,
                    "error": 0.006918641651287333
                },
                "test_0/recall_step": {
                    "mean": 0.43281410675140786,
                    "error": 0.006830568521686287
                },
                "test_0/f1_step": {
                    "mean": 0.4360378905446216,
                    "error": 0.006799074372932923
                }
            },
            "gpt-3.5-turbo-0301": {
                "test_0/precision_step": {
                    "mean": 0.2307701724873305,
                    "error": 0.005763813693488634
                },
                "test_0/recall_step": {
                    "mean": 0.22533572546051445,
                    "error": 0.0057100314210039305
                },
                "test_0/f1_step": {
                    "mean": 0.2264146678689837,
                    "error": 0.0056281804321235
                }
            },
            "davinci-002": {
                "test_0/precision_step": {
                    "mean": 0.006094798019158869,
                    "error": 0.0009884834403594686
                },
                "test_0/recall_step": {
                    "mean": 0.009757120842309683,
                    "error": 0.0014523144505378324
                },
                "test_0/f1_step": {
                    "mean": 0.00667935052077152,
                    "error": 0.0009609717941299173
                }
            },
            "gpt-3.5-turbo-instruct-0914": {
                "test_0/precision_step": {
                    "mean": 0.1775833608872996,
                    "error": 0.005233281641345622
                },
                "test_0/recall_step": {
                    "mean": 0.1752080308094392,
                    "error": 0.005168602817787277
                },
                "test_0/f1_step": {
                    "mean": 0.17417581183595135,
                    "error": 0.00523566307702672
                }
            },
            "gpt-3.5-turbo-0613": {
                "test_0/precision_step": {
                    "mean": 0.2317643155447645,
                    "error": 0.006014371518534345
                },
                "test_0/recall_step": {
                    "mean": 0.2203133437280003,
                    "error": 0.005779634211822926
                },
                "test_0/f1_step": {
                    "mean": 0.223672473524819,
                    "error": 0.005793356467057351
                }
            }
        }
    },
    "CP": {
        "ptb64": {
            "gpt-4-0613": {
                "test/recall_step": {
                    "mean": 0.615562103559516,
                    "error": 0.01605310997779641
                },
                "test/prec_step": {
                    "mean": 0.6430547954030119,
                    "error": 0.015021542414224043
                },
                "test/tag_accracy_step": {
                    "mean": 0.9042310824973046,
                    "error": 0.004883682056972927
                }
            },
            "davinci-002": {
                "test/recall_step": {
                    "mean": 0.3032181092525182,
                    "error": 0.023449144143712686
                },
                "test/prec_step": {
                    "mean": 0.48442596707442037,
                    "error": 0.0243903605879989
                },
                "test/tag_accracy_step": {
                    "mean": 0.36273850276045605,
                    "error": 0.03671645953864677
                }
            },
            "text-davinci-003": {
                "test/recall_step": {
                    "mean": 0.5110087808156978,
                    "error": 0.015410361171310477
                },
                "test/prec_step": {
                    "mean": 0.5127146495560001,
                    "error": 0.013189321477521776
                },
                "test/tag_accracy_step": {
                    "mean": 0.8524019377080002,
                    "error": 0.005860234780515283
                }
            },
            "gpt-3.5-turbo-instruct-0914": {
                "test/recall_step": {
                    "mean": 0.4760656572146223,
                    "error": 0.011246382631237811
                },
                "test/prec_step": {
                    "mean": 0.4855199332182118,
                    "error": 0.010590837587727997
                },
                "test/tag_accracy_step": {
                    "mean": 0.8173238512753063,
                    "error": 0.008697536735345734
                }
            },
            "gpt-3.5-turbo-0613": {
                "test/recall_step": {
                    "mean": 0.5322108549534241,
                    "error": 0.018815378272304395
                },
                "test/prec_step": {
                    "mean": 0.580212097636537,
                    "error": 0.017903100194888943
                },
                "test/tag_accracy_step": {
                    "mean": 0.9175221286068073,
                    "error": 0.002127072486396986
                }
            },
            "gpt-3.5-turbo-0301": {
                "test/recall_step": {
                    "mean": 0.5189172992472014,
                    "error": 0.016440839753939784
                },
                "test/prec_step": {
                    "mean": 0.5683922907176046,
                    "error": 0.016214886416245855
                },
                "test/tag_accracy_step": {
                    "mean": 0.8866493336727165,
                    "error": 0.004801472092036296
                }
            }
        }
    }
}